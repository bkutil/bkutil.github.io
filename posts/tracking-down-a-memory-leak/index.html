<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><title>Tracking down a memory leak | Balázs' blog</title>
<link rel=canonical href=https://balazs.kutilovi.cz/posts/tracking-down-a-memory-leak/><link href=https://balazs.kutilovi.cz/index.xml rel=alternate type=application/rss+xml title="Balázs' blog"><link rel="shortcut icon" type=image/svg+xml href="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20fill=%22none%22%20viewBox=%220%200%2024%2024%22%20stroke-width=%221.5%22%20stroke=%22currentcolor%22%20color=%22grey%22%3E%3Cpath%20stroke-linecap=%22round%22%20stroke-linejoin=%22round%22%20d=%22M10.34%2015.84c-.688-.06-1.386-.09-2.09-.09H7.5a4.5%204.5.0%20110-9h.75c.704.0%201.402-.03%202.09-.09m0%209.18c.253.962.584%201.892.985%202.783.247.55.06%201.21-.463%201.511l-.657.38c-.551.318-1.26.117-1.527-.461a20.845%2020.845.0%2001-1.44-4.282m3.102.069a18.03%2018.03.0%2001-.59-4.59c0-1.586.205-3.124.59-4.59m0%209.18a23.848%2023.848.0%20018.835%202.535M10.34%206.66a23.847%2023.847.0%20008.835-2.535m0%200A23.74%2023.74.0%200018.795%203m.38%201.125a23.91%2023.91.0%20011.014%205.395m-1.014%208.855c-.118.38-.245.754-.38%201.125m.38-1.125a23.91%2023.91.0%20001.014-5.395m0-3.46c.495.413.811%201.035.811%201.73s-.316%201.317-.811%201.73m0-3.46a24.347%2024.347.0%20010%203.46%22/%3E%3C/svg%3E"><style>/*!modern-normalize v2.0.0 | MIT License | https://github.com/sindresorhus/modern-normalize*/*,::before,::after{box-sizing:border-box}html{font-family:system-ui,segoe ui,Roboto,Helvetica,Arial,sans-serif,apple color emoji,segoe ui emoji;line-height:1.15;-webkit-text-size-adjust:100%;-moz-tab-size:4;tab-size:4}body{margin:0}hr{height:0;color:inherit}abbr[title]{text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp,pre{font-family:ui-monospace,SFMono-Regular,Consolas,liberation mono,Menlo,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{text-indent:0;border-color:inherit}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,select{text-transform:none}button,[type=button],[type=reset],[type=submit]{-webkit-appearance:button}::-moz-focus-inner{border-style:none;padding:0}:-moz-focusring{outline:1px dotted ButtonText}:-moz-ui-invalid{box-shadow:none}legend{padding:0}progress{vertical-align:baseline}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}</style><style>html{line-height:1.5}h1{font-size:2.136rem}h2{font-size:1.898rem}h3{font-size:1.688rem}body{max-width:32rem;padding:.74rem;margin:auto}blockquote{margin-left:1.688rem;padding-left:.74rem;border-left:.461rem #ddd solid}p code{font-size:.936rem;margin:0 .288rem}img{max-width:100%;height:auto}pre{font-size:.74rem;margin:1.688rem 0;padding:.936rem;overflow-x:scroll}footer{margin:1.688rem 0}footer nav{margin:1.688rem 0}</style></head><body><header><h1>Balázs' blog</h1><nav><span><a href=/>Posts</a>
</span><span><a href=/about/>About</a></span></nav></header><main><h2>Tracking down a memory leak</h2><time datetime=2024-05-06T11:21:17+02:00>May 6, 2024</time><p>Tl;Dr: <a href=https://dev.37signals.com/adventures-hunting-down-ruby-memory-leak/>I followed this guide</a>
to debug a memory leak in a Sidekiq job. In my case, the leak was
caused by a thread local array buffer in <code>lograge-sql</code> that never got
cleared.</p><p>With <a href="https://plainapm.com?ref=tracking-down-a-memory-leak">PlainAPM</a>
infra moved away from Heroku, one of the first monitors I implemented
were for the app&rsquo;s memory, as previously Heroku metrics showed a
persistent growth for the Sidekiq process:</p><p><picture><source type=image/webp height=1244 width=2496 srcset="/posts/tracking-down-a-memory-leak/heroku-metrics_hu1a82d3e9f59bd53841d04b9a3b977af5_230617_d60b9928c7d1c5ee6b860c5c0b7532ff.webp 1366w,/posts/tracking-down-a-memory-leak/heroku-metrics_hu1a82d3e9f59bd53841d04b9a3b977af5_230617_5b3bb1c942878f09be8ca61ae72c6ed4.webp 1024w,/posts/tracking-down-a-memory-leak/heroku-metrics_hu1a82d3e9f59bd53841d04b9a3b977af5_230617_8cac1fa3d13c495de30fdae1f8235ba5.webp 768w,/posts/tracking-down-a-memory-leak/heroku-metrics_hu1a82d3e9f59bd53841d04b9a3b977af5_230617_6755324745a7442c3c24e260f052bf55.webp 512w,/posts/tracking-down-a-memory-leak/heroku-metrics_hu1a82d3e9f59bd53841d04b9a3b977af5_230617_d23f59d986afd545dd5d8f5c2f832ccd.webp 384w" sizes="calc(32rem - 2 * 0.74rem)"><img alt="Growing memory usage of a Ruby Sidekiq process, Heroku metrics" src=/posts/tracking-down-a-memory-leak/heroku-metrics_hu1a82d3e9f59bd53841d04b9a3b977af5_230617_1440x1440_fit_box_3.png title srcset="/posts/tracking-down-a-memory-leak/heroku-metrics_hu1a82d3e9f59bd53841d04b9a3b977af5_230617_173ce04d6050719d74123b43063c6a91.png 1366w,/posts/tracking-down-a-memory-leak/heroku-metrics_hu1a82d3e9f59bd53841d04b9a3b977af5_230617_03b633e31d8803d5ca0645fa07d22667.png 1024w,/posts/tracking-down-a-memory-leak/heroku-metrics_hu1a82d3e9f59bd53841d04b9a3b977af5_230617_276fdefc34f2d1f74d44e53e705b8575.png 768w,/posts/tracking-down-a-memory-leak/heroku-metrics_hu1a82d3e9f59bd53841d04b9a3b977af5_230617_918268c4f3524814017a1a78a3821f83.png 512w,/posts/tracking-down-a-memory-leak/heroku-metrics_hu1a82d3e9f59bd53841d04b9a3b977af5_230617_312e2bb57969af0f9509fc21422c8ad6.png 384w" height=1244 width=2496 loading=lazy sizes="calc(32rem - 2 * 0.74rem)"></picture></p><p>Initially, I thought it was a memory fragmentation issue, and that the
process is allocating objects in a way that doesn&rsquo;t allow releasing the
memory back to the OS. I tried switching to
<a href=https://github.com/jemalloc/jemalloc>jemalloc</a>, which is supposedly
better at handling fragmentation than the standard malloc, and also has a built-in support
for <a href=https://github.com/jemalloc/jemalloc/wiki/Use-Case%3A-Leak-Checking>leak checking</a>.</p><p>But it didn&rsquo;t help:</p><p><picture><source type=image/webp height=1130 width=2522 srcset="/posts/tracking-down-a-memory-leak/memory-leak-growth_hu8f02a10341ae921e6be7cbe43010e0d8_106203_59c4400778628fc34af4533b348dd062.webp 1366w,/posts/tracking-down-a-memory-leak/memory-leak-growth_hu8f02a10341ae921e6be7cbe43010e0d8_106203_9d59d329620819a65ebde0fa2bb1e7dc.webp 1024w,/posts/tracking-down-a-memory-leak/memory-leak-growth_hu8f02a10341ae921e6be7cbe43010e0d8_106203_8a56064bf6d657f807058d79c0868ea2.webp 768w,/posts/tracking-down-a-memory-leak/memory-leak-growth_hu8f02a10341ae921e6be7cbe43010e0d8_106203_f53d87737dbd0f0826d03808c36bdc63.webp 512w,/posts/tracking-down-a-memory-leak/memory-leak-growth_hu8f02a10341ae921e6be7cbe43010e0d8_106203_b75221066a00bcc7821a973cf86fc27b.webp 384w" sizes="calc(32rem - 2 * 0.74rem)"><img alt="Linearly growing memory usage of a Ruby Sidekiq process, a Grafana chart" src=/posts/tracking-down-a-memory-leak/memory-leak-growth_hu8f02a10341ae921e6be7cbe43010e0d8_106203_1440x1440_fit_box_3.png title srcset="/posts/tracking-down-a-memory-leak/memory-leak-growth_hu8f02a10341ae921e6be7cbe43010e0d8_106203_a0f511bc9165af743a338d97d9fa7d17.png 1366w,/posts/tracking-down-a-memory-leak/memory-leak-growth_hu8f02a10341ae921e6be7cbe43010e0d8_106203_1245e14c17e5d441b329a98927256e44.png 1024w,/posts/tracking-down-a-memory-leak/memory-leak-growth_hu8f02a10341ae921e6be7cbe43010e0d8_106203_dc1abb00a0f69cb556bc31d4c53ce6bb.png 768w,/posts/tracking-down-a-memory-leak/memory-leak-growth_hu8f02a10341ae921e6be7cbe43010e0d8_106203_20737beb05fb1fe2289990caec52070b.png 512w,/posts/tracking-down-a-memory-leak/memory-leak-growth_hu8f02a10341ae921e6be7cbe43010e0d8_106203_9fd446d66a9a99bf6ade40ed1c1debbf.png 384w" height=1130 width=2522 loading=lazy sizes="calc(32rem - 2 * 0.74rem)"></picture></p><p>Luckily, I stumbled upon the above mentioned <a href=https://dev.37signals.com/adventures-hunting-down-ruby-memory-leak/>guide</a>
and from there, things were relatively straight-forward.</p><p>I had it a bit simpler than Jacopo in the original post, as I was
able to reproduce the issue locally, and so did not need to be careful
around production. I installed <code>rbtrace</code> so I could capture heap dumps
from a running process, enabled <code>trace_object_allocations</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-ruby data-lang=ruby><span style=display:flex><span><span style=color:#888># in bin/sidekiq binstub generated by Bundler</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#080;font-weight:700>if</span> <span style=color:#036;font-weight:700>ENV</span>[<span style=color:#d20;background-color:#fff0f0>&#34;TRACE_OBJECT_ALLOCATIONS&#34;</span>]
</span></span><span style=display:flex><span>  <span style=color:#038>require</span> <span style=color:#d20;background-color:#fff0f0>&#34;objspace&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#036;font-weight:700>ObjectSpace</span>.trace_object_allocations_start
</span></span><span style=display:flex><span><span style=color:#080;font-weight:700>end</span>
</span></span></code></pre></div><p>triggered the Sidekiq workload in between the three captures, and used <a href="https://github.com/zombocom/heapy?tab=readme-ov-file">heapy diff</a> on the heap dumps to get the retained objects:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-shell data-lang=shell><span style=display:flex><span>$ heapy diff /tmp/0.json /tmp/1.json /tmp/2.json  | head -10
</span></span><span style=display:flex><span>Retained STRING <span style=color:#00d;font-weight:700>14994</span> objects of size 9596160/9611080 (in bytes) at: /home/plainapm/.gem/ruby/3.3.1/gems/lograge-sql-2.3.2/lib/lograge/sql.rb:53
</span></span><span style=display:flex><span>8&lt; --- snipped <span style=color:#080;font-weight:700>for</span> brevity ---
</span></span></code></pre></div><p>This probably should have been enough to point me to the right direction, but I
continued to follow the blog post, and obtained the address info</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-shell data-lang=shell><span style=display:flex><span>$ grep <span style=color:#d20;background-color:#fff0f0>&#34;file.*lib/lograge/sql.rb.*line.*53&#34;</span> /tmp/2.json | head |  grep -o <span style=color:#d20;background-color:#fff0f0>&#34;address\&#34;:\&#34;[^\&#34;]\+\&#34;&#34;</span>
</span></span><span style=display:flex><span>address<span style=color:#d20;background-color:#fff0f0>&#34;:&#34;</span>0x7fa51f9c0c90<span style=color:#d20;background-color:#fff0f0>&#34;
</span></span></span><span style=display:flex><span><span style=color:#d20;background-color:#fff0f0>address&#34;</span>:<span style=color:#d20;background-color:#fff0f0>&#34;0x7fa51f9c5510&#34;</span>
</span></span><span style=display:flex><span>address<span style=color:#d20;background-color:#fff0f0>&#34;:&#34;</span>0x7fa51f9c6910<span style=color:#d20;background-color:#fff0f0>&#34;
</span></span></span><span style=display:flex><span><span style=color:#d20;background-color:#fff0f0>%&lt; --- snipped for brevity ---
</span></span></span></code></pre></div><p>and the path between the objects with <a href=https://github.com/jhawthorn/sheap>sheap</a>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-shell data-lang=shell><span style=display:flex><span>$ sheap /tmp/0.json /tmp/2.json
</span></span><span style=display:flex><span><span style=color:#369>$before</span>: <span style=color:#888>#&lt;Sheap::Heap (269834 objects)&gt;, $after: #&lt;Sheap::Heap (289990 objects)&gt;, $diff: #&lt;Sheap::Diff (20338 objects)&gt;</span>
</span></span><span style=display:flex><span>irb#1():001&gt; <span style=color:#369>$diff</span>.after.find_path(<span style=color:#369>$diff</span>.after.at(<span style=color:#d20;background-color:#fff0f0>&#34;0x7fa51f9c0c90&#34;</span>))
</span></span><span style=display:flex><span>=&gt;
</span></span><span style=display:flex><span>[<span style=color:#888>#&lt;ROOT vm  (2757 refs)&gt;,</span>
</span></span><span style=display:flex><span> <span style=color:#888>#&lt;DATA 0x7fa5218baa10 ractor (15 refs)&gt;,</span>
</span></span><span style=display:flex><span> <span style=color:#888>#&lt;DATA 0x7fa51fbadf58 VM/thread (10 refs)&gt;,</span>
</span></span><span style=display:flex><span> <span style=color:#888>#&lt;DATA 0x7fa51f92f600 fiber (220 refs)&gt;,</span>
</span></span><span style=display:flex><span> <span style=color:#888>#&lt;HASH 0x7fa51f8ec6c0  (1 refs)&gt;,</span>
</span></span><span style=display:flex><span> <span style=color:#888>#&lt;ARRAY 0x7fa51f950288  (4990 refs)&gt;,</span>
</span></span><span style=display:flex><span> <span style=color:#888>#&lt;STRING 0x7fa51f9c0c90 &#34;&lt;some string&gt;&#34;&gt;]</span>
</span></span></code></pre></div><p>This, and looking into the code finally made me realise what&rsquo;s up:</p><p>I&rsquo;m a big fan of <a href=https://brandur.org/canonical-log-lines>canonical log
lines</a>, so in this case, I was
using <code>lograge</code> to get a single line per request that can be easily parsed
later on.</p><p>To be able to log Rails&rsquo; SQL queries this way, I also added a
<a href=https://github.com/iMacTia/lograge-sql/>lograge-sql</a> gem.</p><p>Under the hood, this library is using an <a href=https://github.com/iMacTia/lograge-sql/blob/c8b11e97f2d827b81179b49b7f1dc8bb72b34999/lib/lograge/active_record_log_subscriber.rb#L47>ActiveRecord event
subscriber</a> to capture SQL queries from the current request. These are stored in a <a href=https://github.com/iMacTia/lograge-sql/blob/c8b11e97f2d827b81179b49b7f1dc8bb72b34999/lib/lograge/sql.rb#L37>thread local
buffer</a>,
which then gets passed over to lograge
through a hook into the <code>extract_request</code> method. In the usual case, e.g. while
processing a request, this would emit the log line, but <a href=https://github.com/iMacTia/lograge-sql/blob/c8b11e97f2d827b81179b49b7f1dc8bb72b34999/lib/lograge/sql/extension.rb#L14-L27>also clear the
store</a>.</p><p>However, grepping and rummaging through the <code>lograge</code> code revealed that
it only
<a href=https://github.com/roidrage/lograge/blob/2839d2c7786ba8b8cf1acb8ca705be1c3ee66e0d/lib/lograge.rb#L134-L135>activates</a>
for <code>ActionController</code> and optionally, <code>ActionCable</code>.</p><p>For <code>ActiveJob</code>, or a class including <code>Sidekiq::Job</code>, <code>extract_request</code>
would never get called, and the buffer would grow indefinitely with every executed
SQL query.</p><p>For now, I fixed the leak by disabling <code>lograge</code> whenever <code>Sidekiq.server?</code> is
not <code>nil</code>. Now, this looks much better:</p><p><picture><source type=image/webp height=1124 width=2492 srcset="/posts/tracking-down-a-memory-leak/memory-leak-fixed_hu4e0ad0121f993aa11788114b93c50723_206318_8d24ed08e369ab788ece81610b207e17.webp 1366w,/posts/tracking-down-a-memory-leak/memory-leak-fixed_hu4e0ad0121f993aa11788114b93c50723_206318_8818f5868aeb1424c7db7e33e2100c4e.webp 1024w,/posts/tracking-down-a-memory-leak/memory-leak-fixed_hu4e0ad0121f993aa11788114b93c50723_206318_f33c35c62c3cea21f8b42bc429da5c5d.webp 768w,/posts/tracking-down-a-memory-leak/memory-leak-fixed_hu4e0ad0121f993aa11788114b93c50723_206318_160b742166ab4643ab6960046f3f1cb2.webp 512w,/posts/tracking-down-a-memory-leak/memory-leak-fixed_hu4e0ad0121f993aa11788114b93c50723_206318_c7a66b166448ef6901d8d5f905fe4cac.webp 384w" sizes="calc(32rem - 2 * 0.74rem)"><img alt="Memory usage chart of a Ruby process staying flat after fix was deployed" src=/posts/tracking-down-a-memory-leak/memory-leak-fixed_hu4e0ad0121f993aa11788114b93c50723_206318_1440x1440_fit_box_3.png title srcset="/posts/tracking-down-a-memory-leak/memory-leak-fixed_hu4e0ad0121f993aa11788114b93c50723_206318_291de3540abc709789823ce650a953e9.png 1366w,/posts/tracking-down-a-memory-leak/memory-leak-fixed_hu4e0ad0121f993aa11788114b93c50723_206318_c7c70f1c665bcca19f16842d63232739.png 1024w,/posts/tracking-down-a-memory-leak/memory-leak-fixed_hu4e0ad0121f993aa11788114b93c50723_206318_64dcf24ff0fde9cc5d25892341dda9cc.png 768w,/posts/tracking-down-a-memory-leak/memory-leak-fixed_hu4e0ad0121f993aa11788114b93c50723_206318_092fcd91fb96e2913600d3c09fc2b708.png 512w,/posts/tracking-down-a-memory-leak/memory-leak-fixed_hu4e0ad0121f993aa11788114b93c50723_206318_bf8f3989568889bcb22bc8383e29edd0.png 384w" height=1124 width=2492 loading=lazy sizes="calc(32rem - 2 * 0.74rem)"></picture></p></main><footer><nav><a href=https://balazs.kutilovi.cz/posts/handling-process-forks-with-threads/>&#171; Handling forks in threaded code in Ruby</a></nav><div><a href=https://balazs.kutilovi.cz/index.xml title="Balázs' blog" target=_blank>RSS</a>
<a href=https://twitter.com/balazs_kutil target=_blank>Twitter</a>
<a rel=me href=https://ruby.social/@balazs target=_blank>Mastodon</a>
<a href=https://linkedin.com/in/balazs-kutil target=_blank>Linkedin</a>
<a href=https://github.com/bkutil target=_blank>GitHub</a></div></footer></body></html>